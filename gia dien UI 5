import cv2
import numpy as np
import streamlit as st
import threading
# Load the pre-trained Haar Cascade Classifier for full body detection
body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')

# Set the desired frame rate
desired_fps = 30
frame_delay = 1.0 / desired_fps  # Calculate the time delay for the desired frame rate

people = []  # List to store detected people
next_person_id = 1  # Initialize unique ID counter
frame_count = 0
frame_skip = 2

# Define two lines for counting people
line1_x = 200  # X-coordinate of the first line
people_in_count = 0
people_out_count = 0
# Danh sách các đối tượng đang được theo dõi, bao gồm ID của từng đối tượng và trạng thái ('in' hoặc 'out')
tracking_objects = {}
next_object_id = 1  # Bắt đầu ID từ 1
# Vẽ đường ngang
def draw_line(image, line):
    cv2.line(image, line[0], line[6], (255, 0, 0), 6)
# Luồng cho việc phát hiện người
def detect_people():
    global enter_count, exit_count, tracking_objects

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (640, 480))
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
# Create a Streamlit web app
st.title("Real-time Person Detection and Counting")

# Create a Streamlit window to display the video stream
video_frame = st.empty()
camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
enter_count = 0
exit_count = 0
while True:
    ret, frame = cap.read()
    frame_count += 1
    if frame_count % frame_skip != 0:
        continue

    if not ret:
        break

    # Convert the frame to grayscale for body detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Perform body detection
    bodies = body_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5, minSize=(40, 40))

    # Update the list of people and draw bounding boxes with IDs, centroids, and counting lines
    for (x, y, w, h) in bodies:
        person_detected = False
        for person in people:
            px, py, pw, ph, pid = person
            # Check if the detected body is close to an existing person
            if abs(x - px) < 20 and abs(y - py) < 20:
                person[0] = x
                person[1] = y
                person_detected = True
                # Draw a bounding box with the person's ID
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(frame, str(pid), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                # Calculate and draw the centroid
                centroid_x = x + w // 2
                centroid_y = y + h
                cv2.circle(frame, (centroid_x, centroid_y), 4, (0, 0, 255), -1)
                # Check if the person is moving in or out
                if y + h < line1_x and py + ph >= line1_x:
                    people_out_count += 1
                if y > line1_x and py <= line1_x:
                    people_in_count += 1
                break
        if not person_detected:
            # Assign a new ID to the detected person and add them to the list
            pid = next_person_id
            next_person_id += 1
            people.append([x, y, w, h, pid])
            # Draw a bounding box with the person's ID
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(frame, str(pid), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            # Calculate and draw the centroid
            centroid_x = x + w // 2
            centroid_y = y + h
            cv2.circle(frame, (centroid_x, centroid_y), 4, (0, 0, 255), -1)
# Kiểm tra xem đối tượng đã được theo dõi chưa
            tracked = False
            object_id = None
            for obj_id, values in tracking_objects.items():
                try:
                    tracker, bbox, prev_centroid, status = values
                    x1, y1, w1, h1 = bbox
                    dist = ((centroid_x - prev_centroid[0]) ** 2 + (centroid_y - prev_centroid[1]) ** 2) ** 0.5
                except:
                    continue

                if dist < 50:  # Thay đổi ngưỡng khoảng cách
                    tracked = True
                    object_id = obj_id
                    break

            if not tracked:
                # Khai báo biến next_object_id ở phạm vi toàn cục   
                next_object_id = 1  # Bắt đầu ID từ 1
                bbox = (x, y, w, h)
                tracker = cv2.TrackerCSRT_create()  # Khởi tạo tracker
                tracking_objects[next_object_id] = (tracker, bbox, (centroid_x, centroid_y), 'out')
                object_id = next_object_id
                next_object_id += 1
                new_object_detected = True  # Đã phát hiện người mới
                # Bắt đầu theo dõi
                tracker.init(frame, bbox)

            if centroid_y < line[0][1] and tracking_objects[object_id][2][1] >= line[0][1] and tracking_objects[object_id][3] != 'in':
                enter_count += 1
                tracking_objects[object_id] = (tracker, bbox, (centroid_x, centroid_y), 'in')  # Cập nhật trạng thái của đối tượng
                message = f"Người {object_id} vào. Tổng số người vào: {enter_count}"
                print(message)  # In ra terminal
            elif centroid_y > line[1][1] and tracking_objects[object_id][2][1] <= line[1][1] and tracking_objects[object_id][3] != 'out':
                exit_count += 1
                tracking_objects[object_id] = (tracker, bbox, (centroid_x, centroid_y), 'out')  # Cập nhật trạng thái của đối tượng
                message = f"Người {object_id} ra. Tổng số người ra: {exit_count}"
                print(message)  # In ra terminal
                # Cập nhật theo dõi
        for obj_id in list(tracking_objects.keys()):
            tracker, bbox, prev_centroid, status = tracking_objects[obj_id]
            success, new_bbox = tracker.update(frame)

            if success:
                (x1, y1, w1, h1) = [int(v) for v in new_bbox]
                tracking_objects[obj_id] = (tracker, new_bbox, (x1 + w1 // 2, y1 + h1 // 2), status)

        cv2.putText(frame, f"Enter: {enter_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.putText(frame, f"Exit: {exit_count}", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
          # Hiển thị ID và trạng thái của từng đối tượng
        for obj_id, (_, bbox, _, status) in tracking_objects.items():
            x1, y1, w1, h1 = bbox
            cv2.rectangle(frame, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 2)  # Vẽ bounding box
            cv2.putText(frame, f"ID: {str(obj_id)} - {status}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)  # Hiển thị ID và trạng thái
            cv2.imshow('Pedestrian Counting', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    # Draw the counting lines
    line1_x = (frame.shape[0] * 3) // 8
    cv2.line(frame, (0, line1_x), (frame.shape[1], line1_x), (0, 0, 255), 2)
    # Điểm đầu và điểm cuối của đường ngang phía trên
    line = [(0, 480 // 6), (640, 480 // 6)]
    tracker = cv2.TrackerCSRT_create()
    # Display the frame with person detection and counting
    cv2.putText(frame, f"People In: {people_in_count}", (7, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    cv2.putText(frame, f"People Out: {people_out_count}", (7, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    # Display the frame in Streamlit
    video_frame.image(frame, channels="BGR", use_column_width=True)

    # Stop the loop if 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
# Bắt đầu luồng phát hiện người
detect_thread = threading.Thread(target=detect_people)
detect_thread.start()
while True:
    # Đọc video và hiển thị trong luồng chính
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.resize(frame, (640, 480))
    cv2.imshow('Pedestrian Counting', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
# Display final counts and cleanup
st.write(f"People In: {people_in_count}")
st.write(f"People Out: {people_out_count}")
st.write("Download the result file below:")
st.markdown("[Download {result_filename}](/{result_filename})")
cap.release()
cv2.destroyAllWindows()
