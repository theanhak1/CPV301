import cv2
import numpy as np
import threading

# Load the body cascade classifier
body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')
cap = cv2.VideoCapture(0)  # Open a video stream from the camera (use ID 0 or replace with a URL if needed)
# Thiết lập kích thước khung hình đầu vào
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Điền vào độ rộng mong muốn
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Điền vào độ cao mong muốn

# Set the desired frame rate
desired_fps = 25
frame_delay = int(1000 / desired_fps)  # Calculate the time delay for the desired frame qrate

# Create a window for displaying the video stream
cv2.namedWindow('Pedestrian Counting', cv2.WINDOW_NORMAL)
cv2.resizeWindow('Pedestrian Counting', 640, 480)

enter_count = 0
exit_count = 0

# Define the line that divides the region of interest
line = [(0, 480 // 3), (640, 480 // 3)]

# Create a dictionary to keep track of detected pedestrians
tracking_objects = {}
next_object_id = 1  # Start with ID 1

# Function to draw a line on the frame
def draw_line(image, line):
    cv2.line(image, line[0], line[1], (255, 0, 0), 2)

# Function to detect and track pedestrians
def detect_people():
    global enter_count, exit_count, tracking_objects, next_object_id  # Declare as global

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (640, 480))
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        draw_line(frame, line)

        bodies = body_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)

        for (x, y, w, h) in bodies:
            centroid_x = x + w // 2
            centroid_y = y + h

            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.circle(frame, (centroid_x, centroid_y), 4, (0, 0, 255), -1)

            tracked = False
            object_id = None
            for obj_id, values in tracking_objects.items():
                try:
                    tracker, bbox, prev_centroid, status = values
                    x1, y1, w1, h1 = bbox
                    dist = ((centroid_x - prev_centroid[0]) ** 2 + (centroid_y - prev_centroid[1]) ** 2) ** 0.5
                except:
                    continue

                if dist < 50:
                    tracked = True
                    object_id = obj_id
                    break

            if not tracked:
                bbox = (x, y, w, h)
                tracker = cv2.TrackerMIL_create()
                tracking_objects[next_object_id] = (tracker, bbox, (centroid_x, centroid_y), 'out')
                object_id = next_object_id
                next_object_id += 1

                # Initialize tracking
                tracker.init(frame, bbox)

            if centroid_y < line[0][1] and tracking_objects[object_id][2][1] >= line[0][1]:
                enter_count += 1
                tracking_objects[object_id] = (tracker, bbox, (centroid_x, centroid_y), 'in')
                message = f"Person {object_id} entered. Total people entered: {enter_count}"
                print(message)
            elif centroid_y > line[1][1] and tracking_objects[object_id][2][1] <= line[1][1]:
                exit_count += 1
                tracking_objects[object_id] = (tracker, bbox, (centroid_x, centroid_y), 'out')
                message = f"Person {object_id} exited. Total people exited: {exit_count}"
                print(message)

        for obj_id in list(tracking_objects.keys()):
            tracker, bbox, prev_centroid, status = tracking_objects[obj_id]
            success, new_bbox = tracker.update(frame)

            if success:
                (x1, y1, w1, h1) = [int(v) for v in new_bbox]
                tracking_objects[obj_id] = (tracker, new_bbox, (x1 + w1 // 2, y1 + h1 // 2), status)

        cv2.putText(frame, f"Enter: {enter_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.putText(frame, f"Exit: {exit_count}", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        for obj_id, (_, bbox, _, status) in tracking_objects.items():
            x1, y1, w1, h1 = bbox
            cv2.rectangle(frame, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 2)
            cv2.putText(frame, f"ID: {str(obj_id)} - {status}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            cv2.imshow('Pedestrian Counting', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

detect_thread = threading.Thread(target=detect_people)
detect_thread.start()

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.resize(frame, (640, 480))
    cv2.imshow('Pedestrian Counting', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

detect_thread.join()
cap.release()
cv2.destroyAllWindows()
